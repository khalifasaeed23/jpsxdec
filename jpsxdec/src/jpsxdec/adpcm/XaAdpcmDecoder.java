/*
 * jPSXdec: PlayStation 1 Media Decoder/Converter in Java
 * Copyright (C) 2007-2023  Michael Sabin
 * All rights reserved.
 *
 * Redistribution and use of the jPSXdec code or any derivative works are
 * permitted provided that the following conditions are met:
 *
 *  * Redistributions may not be sold, nor may they be used in commercial
 *    or revenue-generating business activities.
 *
 *  * Redistributions that are modified from the original source must
 *    include the complete source code, including the source code for all
 *    components used by a binary built from the modified sources. However, as
 *    a special exception, the source code distributed need not include
 *    anything that is normally distributed (in either source or binary form)
 *    with the major components (compiler, kernel, and so on) of the operating
 *    system on which the executable runs, unless that component itself
 *    accompanies the executable.
 *
 *  * Redistributions must reproduce the above copyright notice, this list
 *    of conditions and the following disclaimer in the documentation and/or
 *    other materials provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER
 * OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
 * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
 * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */

package jpsxdec.adpcm;

import java.io.EOFException;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import javax.annotation.CheckForNull;
import javax.annotation.Nonnull;
import javax.sound.sampled.AudioFormat;
import jpsxdec.util.IO;

/** The ultimate XA ADPCM decoder. Based on the code and documentation by
 * Jonathan Atkins and Jac Goudsmit (http://freshmeat.net/projects/cdxa/).
 *<p>
 * Audio data on XA (eXtended Architecture) "Green Book" CDs is encoded using
 * a form of Adaptive Differential Pulse Code Modulation (ADPCM).
 * The Sony PlayStation and Philips CD-i used this disc format for their games.
 *<p>
 * Since the ADPCM data is interleaved, you cannot decode in a streaming fashion
 * as the data is being read. All of SoundUnit #1 must be read and decoded
 * before starting SoundUnit #2. Once all of sound unit #1 has been read, you've
 * already read all the other sound units anyway. Therefore the design requires
 * a buffer.
 *<hr>
 * This class could be designed in one of 5 ways:
 *<ol>
 *<li>The decoder is minimal and writes an array of shorts:
 * (still interleaved stereo because that shouldn't change, but
 * the return of shorts eliminates the need to know about endian-ness)
 * That array of shorts could then be converted to an AudioInputStream
 * by copying to a byte[] array and wrapping with AudioInputStream.
 *<li>Minimal decoder, but writes an array of bytes in the chosen endian order.
 *<li>Minimal decoder, but writes an array of bytes in a predetermined endian order.
 *<li>Decoder does everything and returns an AudioInputStream.
 *<li>Make it work like the rest of the Java audio system and have the class
 *    implement TargetDataLine.
 *</ol>
 * This has been implemented using the 3rd method, in little-endian order.
 */
public class XaAdpcmDecoder {

    // =========================================================================
    // static

    /** The number of Sound Groups in a ADPCM audio sector = 18. */
    public static final int ADPCM_SOUND_GROUPS_PER_SECTOR = 18;

    public static final int SIZEOF_SOUND_GROUP = 128;

    /** When the audio is stored in 8 bits/sample, the audio is interleaved
     * between 4 sound units. For 8 bits/sample, there are only 4 sound units
     * that each produce 28 PCM samples. */
    static final int SOUND_UNITS_IN_8_BIT_SOUND_GROUP = 4;
    /** When the audio is stored in 4 bits/sample, the audio is interleaved
     * between 8 sound units. For 4 bits/sample, there are 8 sound units that
     * each produce 28 PCM samples. */
    static final int SOUND_UNITS_IN_4_BIT_SOUND_GROUP = 8;

    /** The number of PCM sample frames generated by a XA ADPCM audio sector.
     * @param iAdpcmBitsPerSample Either 4 or 8. */
    public static int pcmSampleFramesGeneratedFromXaAdpcmSector(int iAdpcmBitsPerSample, boolean blnStereo) {
        int iSoundUnitCount;
        switch (iAdpcmBitsPerSample) {
            case 4:
                iSoundUnitCount = SOUND_UNITS_IN_4_BIT_SOUND_GROUP;
                break;
            case 8:
                iSoundUnitCount = SOUND_UNITS_IN_8_BIT_SOUND_GROUP;
                break;
            default:
                throw new IllegalArgumentException("Invalid bits/sample " + iAdpcmBitsPerSample);
        }
        int iSamplesPerFrame = blnStereo ? 2 : 1;
        return ADPCM_SOUND_GROUPS_PER_SECTOR  *
               SoundUnitDecoder.SAMPLES_PER_SOUND_UNIT *
               iSoundUnitCount /
               iSamplesPerFrame;
    }


    // =========================================================================
    // instance

    private final boolean _blnIsStereo;
    private final int _iAdpcmBitsPerSample;

    /** Context for the left channel when stereo, or the only channel when mono. */
    @Nonnull
    private final AdpcmContext _leftOrMonoContext;
    /** Context for the right channel when stereo. */
    @CheckForNull
    private final AdpcmContext _rightContext;

    /** Buffer decoded PCM audio for the left channel when stereo or only channel when mono. */
    @Nonnull
    private final short[] _asiLeftOrMonoPcmBuffer;
    /** Buffer decoded PCM audio for the right channel when stereo. */
    @CheckForNull
    private final short[] _asiRightPcmBuffer;

    /** Length will be the number of sound units per sound group.
     * @see #SOUND_UNITS_IN_4_BIT_SOUND_GROUP
     * @see #SOUND_UNITS_IN_8_BIT_SOUND_GROUP */
    @Nonnull
    private final XaAdpcmSoundUnitDecoder[] _aoSoundUnitDecoders;
    private final byte[] _abParameterBuffer = new byte[16];

    /** Keeps track of the state of the decoding process so loggers can
     * more clearly report the state. */
    private final LogContext _logContext = new LogContext();
    public static class LogContext implements IContextCopier {
        /** The number of PCM sample frames that have been written to the output
         * stream (i.e. a stereo sample frame is only 1 sample frame).
         * Used to help find where in the output stream to look for corruption. */
        public long lngSampleFramesWritten;
        /** The sector number being decoded if available. */
        public int iSourceSector;
        /** The sound group being decoded. */
        public int iSoundGroup;
        /** The sound unit being decoded. */
        public int iSoundUnit;
        /** Set if the last call to
         * {@link #decode(java.io.InputStream, java.io.OutputStream, int)}
         * encountered corruption in the sound parameters. */
        public boolean blnHadCorruption;

        public LogContext() {
            iSourceSector = -1;
            iSoundGroup = -1;
            iSoundUnit = -1;
            lngSampleFramesWritten = 0;
            blnHadCorruption = false;
        }

        @Override
        public @Nonnull LogContext copy() {
            LogContext cpy = new LogContext();
            cpy.lngSampleFramesWritten = lngSampleFramesWritten;
            cpy.iSourceSector = iSourceSector;
            cpy.iSoundGroup = iSoundGroup;
            cpy.iSoundUnit = iSoundUnit;
            cpy.blnHadCorruption = blnHadCorruption;
            return cpy;
        }

        /** Reset at every decode call. */
        public void decodeReset(int iSector) {
            iSourceSector = iSector;
            iSoundGroup = -1;
            iSoundUnit = -1;
            blnHadCorruption = false;
        }

        @Override
        public String toString() {
            String s = String.format(
                    "Sector %d Sound Group.Unit %d.%d after Sample Frame %d",
                    iSourceSector, iSoundGroup, iSoundUnit, lngSampleFramesWritten);
            if (blnHadCorruption)
                return s + " [corruption]";
            else
                return s;
        }
    }

    /**
     * Creates a XA ADPCM decoder for the supplied input format
     * (bits/sample and stereo) and will write the decoded PCM audio with the
     * supplied volume. Audio scaling occurs before clamping for better quality.
     *
     * @param iAdpcmBitsPerSample  ADPCM bits per sample: either 4 or 8.
     * @param blnIsStereo          true for stereo, false for mono.
     * @param dblVolume            Audio scaled by this amount.
     */
    public XaAdpcmDecoder(int iAdpcmBitsPerSample, boolean blnIsStereo, double dblVolume)
    {
        // bits/sample determines the number of sound units per sound group
        int iSoundUnitsPerSoundGroup;
        if (iAdpcmBitsPerSample == 8)
            iSoundUnitsPerSoundGroup = SOUND_UNITS_IN_8_BIT_SOUND_GROUP;
        else if (iAdpcmBitsPerSample == 4)
            iSoundUnitsPerSoundGroup = SOUND_UNITS_IN_4_BIT_SOUND_GROUP;
        else
            throw new IllegalArgumentException("Invalid bits per sample " + iAdpcmBitsPerSample);

        _aoSoundUnitDecoders = new XaAdpcmSoundUnitDecoder[iSoundUnitsPerSoundGroup];
        for (int iSoundUnitIndex = 0; iSoundUnitIndex < _aoSoundUnitDecoders.length; iSoundUnitIndex++) {
            _aoSoundUnitDecoders[iSoundUnitIndex] = new XaAdpcmSoundUnitDecoder(iSoundUnitIndex);
        }

        _iAdpcmBitsPerSample = iAdpcmBitsPerSample;
        _blnIsStereo = blnIsStereo;

        // create a context for each channel (one for mono, two for stereo)
        _leftOrMonoContext = new AdpcmContext(dblVolume);
        _asiLeftOrMonoPcmBuffer = new short[SoundUnitDecoder.SAMPLES_PER_SOUND_UNIT];
        if (_blnIsStereo) {
            _rightContext = new AdpcmContext(dblVolume);
            _asiRightPcmBuffer = new short[SoundUnitDecoder.SAMPLES_PER_SOUND_UNIT];
        } else {
            _rightContext = null;
            _asiRightPcmBuffer = null;
        }

    }

    /** Returns the volume scale that PCM samples are multiplied by before being clamped. */
    public double getVolume() {
        // assume same volume for right channel as well (if it has one)
        return _leftOrMonoContext.getVolumeScale();
    }

    public int getAdpcmBitsPerSample() {
        return _iAdpcmBitsPerSample;
    }

    /** Returns if the decoder is outputting stereo audio. */
    public boolean isStereo() {
        return _blnIsStereo;
    }

    public int getSampleFrameSize() {
        return isStereo() ? 4 : 2;
    }

    /** Returns the number of PCM sample frames that have been written to the
     * output stream (i.e. a stereo sample frame is only 1 sample frame).
     * Reset when {@link #resetContext()} is called. */
    public long getSampleFramesWritten() {
        return _logContext.lngSampleFramesWritten;
    }

    /** Returns if the last call to
     * {@link #decode(java.io.InputStream, java.io.OutputStream, int)}
     * encountered corruption in the sound parameters. */
    public boolean hadCorruption() {
        return _logContext.blnHadCorruption;
    }

    /** Creates an audio format for this decoder.
     * The sample rate must be provided since the decoder doesn't track it. */
    public @Nonnull AudioFormat getOutputFormat(int iSampleFramesPerSecond) {
        return new AudioFormat(iSampleFramesPerSecond, 16, _blnIsStereo ? 2 : 1, true, false);
    }

    /** Decodes a sector's worth of ADPCM data.
     *  Reads 2304 bytes and writes either 4032 or 8064 bytes.
     * @param iSourceSector Optional original sector the ADPCM data came from.
     *                      Only used for logging.
     */
    public void decode(@Nonnull InputStream inStream, @Nonnull OutputStream out,
                       int iSourceSector)
            throws IOException
    {
        _logContext.decodeReset(iSourceSector);
        // There are 18 sound groups,
        // each having  16 bytes of interleaved sound parameters,
        //         and 112 bytes of interleaved ADPCM data
        // ( 18*(16+112) = 2304 bytes will be read )
        for (_logContext.iSoundGroup = 0;
             _logContext.iSoundGroup < ADPCM_SOUND_GROUPS_PER_SECTOR;
             _logContext.iSoundGroup++)
        {
            decodeSoundGroup(inStream, out);
        }
        _logContext.iSourceSector = -1;
        _logContext.iSoundGroup = -1;
    }

    /** Reads 16 bytes of interleaved sound parameters, followed by
     *  112 bytes of interleaved ADPCM sound units. */
    private void decodeSoundGroup(@Nonnull InputStream inStream,
                                  @Nonnull OutputStream out)
            throws IOException
    {
        IO.readByteArray(inStream, _abParameterBuffer);

        if (_iAdpcmBitsPerSample == 4)
            deinterleave4BitsPerSampleSoundGroup(inStream);
        else // == 8
            deinterleave8BitsPerSampleSoundGroup(inStream);

        // read decoded samples and write them to the output stream
        if (_blnIsStereo) {
            for (int iSoundUnit = 0; iSoundUnit < _aoSoundUnitDecoders.length; iSoundUnit+=2) {
                _logContext.iSoundUnit = iSoundUnit;
                XaAdpcmSoundUnitDecoder leftSoundUnit  = _aoSoundUnitDecoders[iSoundUnit];
                leftSoundUnit.decodeSoundUnit(_leftOrMonoContext, _asiLeftOrMonoPcmBuffer, _logContext);

                _logContext.iSoundUnit = iSoundUnit+1;
                XaAdpcmSoundUnitDecoder rightSoundUnit = _aoSoundUnitDecoders[iSoundUnit+1];
                rightSoundUnit.decodeSoundUnit(_rightContext, _asiRightPcmBuffer, _logContext);

                _logContext.iSoundUnit = -1;

                for (int iSample = 0;
                     iSample < SoundUnitDecoder.SAMPLES_PER_SOUND_UNIT;
                     iSample++, _logContext.lngSampleFramesWritten++)
                {
                    IO.writeInt16LE(out, _asiLeftOrMonoPcmBuffer[iSample]);
                    IO.writeInt16LE(out, _asiRightPcmBuffer[iSample]);
                }

            }
        } else {
            for (int iSoundUnit = 0; iSoundUnit < _aoSoundUnitDecoders.length; iSoundUnit++) {
                _logContext.iSoundUnit = iSoundUnit;
                XaAdpcmSoundUnitDecoder soundUnit = _aoSoundUnitDecoders[iSoundUnit];
                soundUnit.decodeSoundUnit(_leftOrMonoContext, _asiLeftOrMonoPcmBuffer, _logContext);

                _logContext.iSoundUnit = -1;

                for (int iSample = 0;
                     iSample < SoundUnitDecoder.SAMPLES_PER_SOUND_UNIT;
                     iSample++, _logContext.lngSampleFramesWritten++)
                {
                    IO.writeInt16LE(out, _asiLeftOrMonoPcmBuffer[iSample]);
                }
            }
        }
    }

    /** Reads the sound parameters and ADPCM data for sound groups with
     * 4 bits per sample and stores the result in the {@link #_aoSoundUnitDecoders}
     * array. */
    private void deinterleave4BitsPerSampleSoundGroup(@Nonnull InputStream inStream)
            throws EOFException, IOException
    {
        // Process the 16 byte sound parameters at the
        // start of each sound group
        // the 8 sound parameters (one for each sound unit)
        // are repeated twice, and are ordered like this:
        // 0,1,2,3, 0,1,2,3, 4,5,6,7, 4,5,6,7
        for (int iSoundUnit = 0; iSoundUnit < 4; iSoundUnit++) {
            _logContext.iSoundUnit = iSoundUnit;
            _aoSoundUnitDecoders[iSoundUnit].addSoundParameter(_abParameterBuffer[iSoundUnit] & 0xff);
            _aoSoundUnitDecoders[iSoundUnit].addSoundParameter(_abParameterBuffer[iSoundUnit+4] & 0xff);

            _logContext.iSoundUnit = iSoundUnit + 4;
            _aoSoundUnitDecoders[iSoundUnit+4].addSoundParameter(_abParameterBuffer[iSoundUnit+8] & 0xff);
            _aoSoundUnitDecoders[iSoundUnit+4].addSoundParameter(_abParameterBuffer[iSoundUnit+12] & 0xff);
        }
        _logContext.iSoundUnit = -1;

        // de-interleave the sound units
        for (int iSampleIdx = 0; iSampleIdx < SoundUnitDecoder.SAMPLES_PER_SOUND_UNIT; iSampleIdx++)
        {
            // read a sample for each of the 8 sound units
            // 1 byte produces 2 samples, but for different sound units
            // sound unit nibbles are interleaved like this:
            // high nibble: sound unit 1, low nibble: sound unit 0
            // high nibble: sound unit 3, low nibble: sound unit 2
            // high nibble: sound unit 5, low nibble: sound unit 4
            // high nibble: sound unit 7, low nibble: sound unit 6
            // high nibble: sound unit 1, low nibble: sound unit 0
            // ...
            for (_logContext.iSoundUnit = 0; _logContext.iSoundUnit < 8;)
            {
                int iByte = inStream.read();
                if (iByte < 0)
                    throw new EOFException();

                short siADPCMSample;
                // shift the nibble into the top of a short
                siADPCMSample = (short)((iByte & 0x0F) << 12);
                _aoSoundUnitDecoders[_logContext.iSoundUnit].addShiftedAdpcmSample(siADPCMSample);
                _logContext.iSoundUnit++;
                // shift the nibble into the top of a short
                siADPCMSample = (short)((iByte & 0xF0) << 8);
                _aoSoundUnitDecoders[_logContext.iSoundUnit].addShiftedAdpcmSample(siADPCMSample);
                _logContext.iSoundUnit++;
            }
            _logContext.iSoundUnit = -1;
        }
    }

    /** Reads the sound parameters and ADPCM data for sound groups with
     * 8 bits per sample and stores the result in the {@link #_aoSoundUnitDecoders}
     * array. */
    private void deinterleave8BitsPerSampleSoundGroup(@Nonnull InputStream inStream)
            throws EOFException, IOException
    {
        // Process the 16 byte sound parameters at the
        // start of each sound group
        // the 4 sound parameters (one for each sound unit)
        // are repeated four times and are ordered like this:
        // 0,1,2,3, 0,1,2,3, 0,1,2,3, 0,1,2,3
        for (_logContext.iSoundUnit = 0; _logContext.iSoundUnit < 4; _logContext.iSoundUnit++) {
            XaAdpcmSoundUnitDecoder soundUnit = _aoSoundUnitDecoders[_logContext.iSoundUnit];
            for (int iRepeat = _logContext.iSoundUnit; iRepeat < 16; iRepeat+=4) {
                soundUnit.addSoundParameter(_abParameterBuffer[iRepeat] & 0xff);
            }
        }
        _logContext.iSoundUnit = -1;

        // de-interleave the sound units
        for (int iSampleIdx = 0; iSampleIdx < SoundUnitDecoder.SAMPLES_PER_SOUND_UNIT; iSampleIdx++)
        {
            // read a sample for each of the 4 sound units
            // 1 byte produces 1 sample
            // sound unit bytes are interleaved like this:
            // sound unit 0, sound unit 1, sound unit 2, sound unit 3,
            // sound unit 0, sound unit 1, sound unit 2, sound unit 3,
            // ...
            for (_logContext.iSoundUnit = 0; _logContext.iSoundUnit < 4; _logContext.iSoundUnit++)
            {
                int iByte = inStream.read();
                if (iByte < 0)
                    throw new EOFException();

                _aoSoundUnitDecoders[_logContext.iSoundUnit].addShiftedAdpcmSample(
                        (short)(iByte << 8)); // shift the byte into the top of a short
            }
            _logContext.iSoundUnit = -1;
        }
    }


    /** Sound unit found in a sound group.
     * Feed it parameters and ADPCM samples then decode the result. */
    private static class XaAdpcmSoundUnitDecoder {

        /** Not used, but useful when debugging. */
        private final int _iSoundUnitIndex;
        private final SoundUnitDecoder _soundUnitDecoder = new SoundUnitDecoder(K0K1Filter.XA);

        private XaAdpcmSoundUnit.Builder _soundUnitBuilder = new XaAdpcmSoundUnit.Builder();

        /** @param iSoundUnitIndex Sound unit number. */
        public XaAdpcmSoundUnitDecoder(int iSoundUnitIndex) {
            _iSoundUnitIndex = iSoundUnitIndex;
        }

        /** @param iSoundParameter  An unsigned byte value as read from the
         *                          source stream, holding the range and
         *                          filter parameters for this sound unit. */
        public void addSoundParameter(int iSoundParameter) {
            _soundUnitBuilder.addRedundantParameter(iSoundParameter);
        }

        private void addShiftedAdpcmSample(short s) {
            _soundUnitBuilder.addShiftedAdpcmSample(s);
        }

        private void decodeSoundUnit(@Nonnull AdpcmContext context,
                                     @Nonnull short[] asiOutPcmBuffer,
                                     @Nonnull LogContext logContext)
        {
            XaAdpcmSoundUnit su = _soundUnitBuilder.build(logContext);
            _soundUnitDecoder.decodeSoundUnit(context, su, asiOutPcmBuffer, logContext);
            // reset the builder
            _soundUnitBuilder = new XaAdpcmSoundUnit.Builder();
        }

    }

}
